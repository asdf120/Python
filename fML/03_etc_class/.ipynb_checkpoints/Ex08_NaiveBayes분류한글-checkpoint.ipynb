{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고-예제] 2중 반복\n",
    "\n",
    "result = [x*y for x in range(2,10) for y in range(1,10)]\n",
    "\n",
    "[2, 4, 6, 8, 10, 12, 14, 16, 18, 3, 6, 9, 12, 15, 18, 21, 24, 27, 4, 8, 12, 16,\n",
    "20, 24, 28, 32, 36, 5, 10, 15, 20, 25, 30, 35, 40, 45, 6, 12, 18, 24, 30, 36, 42\n",
    ", 48, 54, 7, 14, 21, 28, 35, 42, 49, 56, 63, 8, 16, 24, 32, 40, 48, 56, 64, 72,\n",
    "9, 18, 27, 36, 45, 54, 63, 72, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kosmo_04\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# 2020.07 실행시 에러 발생하여 추가\n",
    "nltk.download('punkt')\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 훈련데이타 \"\"\"\n",
    "\n",
    "train = [('메리가 좋아', 'pos'), \n",
    "         ('고양이도 좋아', 'pos'),\n",
    "         ('난 수업이 지루해', 'neg'),\n",
    "         ('메리는 이쁜 고양이야', 'pos'),\n",
    "         ('난 마치고 메리랑 놀거야', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도',\n",
       " '고양이야',\n",
       " '난',\n",
       " '놀거야',\n",
       " '마치고',\n",
       " '메리가',\n",
       " '메리는',\n",
       " '메리랑',\n",
       " '수업이',\n",
       " '이쁜',\n",
       " '좋아',\n",
       " '지루해'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train \n",
    "                        for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'메리는': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False,\n",
       "   '메리가': True,\n",
       "   '메리랑': False,\n",
       "   '고양이야': False,\n",
       "   '놀거야': False,\n",
       "   '고양이도': False,\n",
       "   '지루해': False,\n",
       "   '난': False,\n",
       "   '마치고': False,\n",
       "   '좋아': True},\n",
       "  'pos'),\n",
       " ({'메리는': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False,\n",
       "   '메리가': False,\n",
       "   '메리랑': False,\n",
       "   '고양이야': False,\n",
       "   '놀거야': False,\n",
       "   '고양이도': True,\n",
       "   '지루해': False,\n",
       "   '난': False,\n",
       "   '마치고': False,\n",
       "   '좋아': True},\n",
       "  'pos'),\n",
       " ({'메리는': False,\n",
       "   '수업이': True,\n",
       "   '이쁜': False,\n",
       "   '메리가': False,\n",
       "   '메리랑': False,\n",
       "   '고양이야': False,\n",
       "   '놀거야': False,\n",
       "   '고양이도': False,\n",
       "   '지루해': True,\n",
       "   '난': True,\n",
       "   '마치고': False,\n",
       "   '좋아': False},\n",
       "  'neg'),\n",
       " ({'메리는': True,\n",
       "   '수업이': False,\n",
       "   '이쁜': True,\n",
       "   '메리가': False,\n",
       "   '메리랑': False,\n",
       "   '고양이야': True,\n",
       "   '놀거야': False,\n",
       "   '고양이도': False,\n",
       "   '지루해': False,\n",
       "   '난': False,\n",
       "   '마치고': False,\n",
       "   '좋아': False},\n",
       "  'pos'),\n",
       " ({'메리는': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False,\n",
       "   '메리가': False,\n",
       "   '메리랑': True,\n",
       "   '고양이야': False,\n",
       "   '놀거야': True,\n",
       "   '고양이도': False,\n",
       "   '지루해': False,\n",
       "   '난': True,\n",
       "   '마치고': True,\n",
       "   '좋아': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n",
    "                                                        for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이브베이즈 분류기\n",
    "cls = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '난 수업이'\n",
    "\n",
    "test_dic = {word.lower() :(word in word_tokenize(test_sentence.lower()))\n",
    "               for word in all_words}\n",
    "\n",
    "\n",
    "cls.classify(test_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 형태소 분석을 한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['메리/Noun', '가/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['고양이/Noun', '도/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['난/Noun', '수업/Noun', '이/Josa', '지루하다/Adjective'], 'neg'),\n",
       " (['메리/Noun', '는/Josa', '이쁘다/Adjective', '고양이/Noun', '야/Josa'], 'pos'),\n",
       " (['난/Noun', '마치/Noun', '고/Josa', '메리/Noun', '랑/Josa', '놀다/Verb'], 'pos')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# github의 Lucy Park 님의 코드에 따르면 태그를 붙여주는 것이 좋다고 권장함\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]\n",
    "train_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메리/Noun',\n",
       " '가/Josa',\n",
       " '좋다/Adjective',\n",
       " '고양이/Noun',\n",
       " '도/Josa',\n",
       " '좋다/Adjective',\n",
       " '난/Noun',\n",
       " '수업/Noun',\n",
       " '이/Josa',\n",
       " '지루하다/Adjective',\n",
       " '메리/Noun',\n",
       " '는/Josa',\n",
       " '이쁘다/Adjective',\n",
       " '고양이/Noun',\n",
       " '야/Josa',\n",
       " '난/Noun',\n",
       " '마치/Noun',\n",
       " '고/Josa',\n",
       " '메리/Noun',\n",
       " '랑/Josa',\n",
       " '놀다/Verb']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용되는 전체 단어(말뭉치) 찾기\n",
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-438126c74626>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-438126c74626>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    train_xy [(term_exists(d),c) for d, c in train_docs]\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 훈련문장의 단어들이 전체 단어(말뭉치)에 있는 단어인지 확인\n",
    "# 명사와 조사를 구분하여 판독이 용이\n",
    "def term_exists(doc):\n",
    "    return {word: (word in set(doc)) for word in tokens}\n",
    "\n",
    "train_xy [(term_exists(d),c) for d, c in train_docs]\n",
    "train_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
